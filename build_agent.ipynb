{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ee4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from operator import add as add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.tools import tool\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4beaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    "    collection_name=\"prototype\",\n",
    "    embedding_function=embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What are risk factors?\")\n",
    "for d in docs:\n",
    "    print(d.metadata.get(\"page\"), d.page_content[:150])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4498d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff008bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_retriever(state: AgentState)->AgentState:\n",
    "    query = state[\"messages\"][-1].content\n",
    "    print(f\"Query: {query}\")\n",
    "    docs = retriever.invoke(query)\n",
    "    relevant_content = \"\"\n",
    "    for item in docs:\n",
    "        metadata = item.metadata\n",
    "        page_label = metadata['page_label']\n",
    "        page_content = item.page_content\n",
    "        relevant_content+=f\"Page No:- {page_label}\\n{page_content}\\n------------------------------------------\\n\"\n",
    "    # Return a human message (correct format)\n",
    "    return {\"messages\": [HumanMessage(content=relevant_content)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_path = os.path.join(base_path, \"meta_k10.json\")\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta_k10 = json.load(f)\n",
    "    meta_k10 = {int(k): v for k, v in meta_k10.items()}\n",
    "\n",
    "print(\"Loaded JSON with\", len(meta_k10), \"pages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def page_retriever_tool(page_no: int) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the full text content of a specific page from the Meta K-10 document.\n",
    "\n",
    "    Args:\n",
    "        page_no (int): The page number to retrieve (1-based index).\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the complete text of the requested page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        page_content = meta_k10[page_no]\n",
    "        return f\"The Content of Page {page_no} is:\\n-----\\n{page_content}\\n-----\\n\"\n",
    "    except:\n",
    "        return f\"No Content found for Page {page_no}.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cad604",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def context_retriever_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant chunks from the document for a given natural language query.\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The natural language query used to fetch relevant chunks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A formatted string containing page numbers and associated text content\n",
    "        from the retrieved documents. Each chunk is separated by a dashed line.\n",
    "    \"\"\"\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "    relevant_content = \"\"\n",
    "\n",
    "    for item in docs:\n",
    "        metadata = item.metadata or {}\n",
    "        page_label = metadata.get(\"page_label\", \"Unknown Page\")\n",
    "        page_content = item.page_content\n",
    "\n",
    "        relevant_content += (\n",
    "            f\"Page No: {page_label}\\n\"\n",
    "            f\"{page_content}\\n\"\n",
    "            \"------------------------------------------\\n\"\n",
    "        )\n",
    "\n",
    "    return relevant_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"\n",
    "    Add two numbers.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "        float: The result of x + y.\n",
    "    \"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "@tool\n",
    "def sub(x: float, y: float) -> float:\n",
    "    \"\"\"\n",
    "    Subtract two numbers.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "        float: The result of x - y.\n",
    "    \"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "@tool\n",
    "def mul(x: float, y: float) -> float:\n",
    "    \"\"\"\n",
    "    Multiply two numbers.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "        float: The result of x * y.\n",
    "    \"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "@tool\n",
    "def div(x: float, y: float) -> float:\n",
    "    \"\"\"\n",
    "    Divide two numbers.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number (must not be zero).\n",
    "\n",
    "    Returns:\n",
    "        float: The result of x / y.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If y == 0.\n",
    "    \"\"\"\n",
    "    if y == 0:\n",
    "        raise ValueError(\"Division by zero is not allowed.\")\n",
    "    return x / y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2be4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [page_retriever_tool,context_retriever_tool,add,sub,div,mul]\n",
    "llm = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def should_continue(state: AgentState):\n",
    "#     \"\"\"Return True if the last AI message triggered tool calls.\"\"\"\n",
    "#     last_msg = state['messages'][-1]\n",
    "#     return hasattr(last_msg, \"tool_calls\") and bool(last_msg.tool_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(state: AgentState):\n",
    "    \"\"\"\n",
    "    Decide where to route based on the LLM tool calls.\n",
    "\n",
    "    Returns:\n",
    "        \"retriever\" if any retriever tool is called\n",
    "        \"calculator\" if any calculator tool is called\n",
    "        \"none\" if no tool calls exist\n",
    "    \"\"\"\n",
    "\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "\n",
    "    if not hasattr(last_msg, \"tool_calls\") or not last_msg.tool_calls:\n",
    "        return \"none\"\n",
    "\n",
    "    # Check each tool call\n",
    "    for tc in last_msg.tool_calls:\n",
    "        tool_name = tc[\"name\"]\n",
    "\n",
    "        if tool_name in [\"page_retriever_tool\",\"context_retriever_tool\"]:\n",
    "            return \"retriever\"\n",
    "\n",
    "        if tool_name in [\"add\", \"sub\", \"mul\", \"div\"]:\n",
    "            return \"calculator\"\n",
    "\n",
    "    return \"none\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an intelligent AI assistant who answers questions about the Meta Platforms, Inc. 10-K filing.\n",
    "\n",
    "You will now receive only the user's query (no pre-extracted context).\n",
    "Your job is to determine which tool to call based on the user's request.\n",
    "\n",
    "Available tools:\n",
    "- context_retriever_tool → returns only relevant text chunks, not full pages\n",
    "- page_retriever_tool → returns complete pages for given page numbers\n",
    "- Calculator tools (add, sub, mul, div) → must be used for all numeric reasoning and calculations\n",
    "\n",
    "Your responsibilities:\n",
    "\n",
    "1. Determine what information is needed to answer the user's query.\n",
    "\n",
    "2. If needed, call `context_retriever_tool` to identify relevant chunks.\n",
    "   - This tool returns partial context; inspect the chunk metadata (page_number).\n",
    "   - If the chunk appears truncated, incomplete, or insufficient for a correct answer:\n",
    "       → Use `page_retriever_tool` to retrieve the full page.\n",
    "   - If the content appears to continue across pages (e.g., tables, sections):\n",
    "       → Also fetch adjacent pages.\n",
    "\n",
    "3. When the user question requires calculations:\n",
    "   - ALWAYS use the calculator tool (add/sub/mul/div).\n",
    "   - NEVER perform arithmetic manually.\n",
    "\n",
    "4. After retrieving all necessary information:\n",
    "   - Synthesize a final answer strictly based on the retrieved pages and calculator outputs.\n",
    "   - Clearly cite the page numbers used.\n",
    "   - Do not hallucinate or infer information not retrieved.\n",
    "\n",
    "5. Only produce a final natural-language answer when no further tool calls are required.\n",
    "\n",
    "Always rely strictly on retrieval and calculator tools.\n",
    "Never guess. Never answer based on incomplete evidence.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_dict = {our_tool.name: our_tool for our_tool in tools} # Creating a dictionary of our tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be58eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM_Agent\n",
    "def call_llm(state: AgentState)->AgentState:\n",
    "    \"\"\"Function to call the LLM with the current state.\"\"\"\n",
    "    messages = list(state['messages'])\n",
    "    messages = [SystemMessage(content=system_prompt)]+messages[:-1]+[messages[-1]]\n",
    "    response = llm.invoke(messages)\n",
    "    return {'messages':[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever Agent\n",
    "def retrieve_document(state: AgentState)->AgentState:\n",
    "    \"\"\"Execute Page Retriver from the LLM's response.\"\"\"\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    results = []\n",
    "    print(f\"Tool Calls: \",tool_calls)\n",
    "    for t in tool_calls:\n",
    "        print(f\"Calling Tool: {t['name']} with query: {t['args']}\")\n",
    "        \n",
    "        if not t['name'] in tools_dict: # Checks if a valid tool is present\n",
    "            print(f\"\\nTool: {t['name']} does not exist.\")\n",
    "            result = \"Incorrect Tool Name, Please Retry and Select tool from List of Available tools.\"\n",
    "        \n",
    "        else:\n",
    "            result = tools_dict[t['name']].invoke(t['args'])\n",
    "            print(f\"Result length: {len(str(result))}\")\n",
    "            \n",
    "\n",
    "        # Appends the Tool Message\n",
    "        results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "\n",
    "    print(\"Tools Execution Complete. Back to the model!\")\n",
    "    return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculator Agent\n",
    "def calculate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Executes calculator tool calls triggered by the LLM.\n",
    "    \n",
    "    This agent handles tool calls such as add, sub, mul, and div.\n",
    "    For each tool call:\n",
    "      - Validates the tool name\n",
    "      - Executes the tool with provided arguments\n",
    "      - Returns a ToolMessage back to the LLM\n",
    "\n",
    "    Returns:\n",
    "        AgentState: Contains ToolMessage objects for each executed tool.\n",
    "    \"\"\"\n",
    "\n",
    "    last_ai_msg = state[\"messages\"][-1]\n",
    "    tool_calls = last_ai_msg.tool_calls\n",
    "    results = []\n",
    "\n",
    "    print(f\"\\nTool Calls Received: {tool_calls}\")\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        args = tool_call[\"args\"]\n",
    "        call_id = tool_call[\"id\"]\n",
    "\n",
    "        print(f\"→ Calling tool '{tool_name}' with args: {args}\")\n",
    "\n",
    "        # Handle invalid tool names\n",
    "        if tool_name not in tools_dict:\n",
    "            result_text = f\"Error: Tool '{tool_name}' not found. Valid tools: {list(tools_dict.keys())}\"\n",
    "            print(result_text)\n",
    "\n",
    "        else:\n",
    "            # Execute tool\n",
    "            try:\n",
    "                result_text = tools_dict[tool_name].invoke(args)\n",
    "            except Exception as e:\n",
    "                result_text = f\"Tool '{tool_name}' failed: {str(e)}\"\n",
    "                print(result_text)\n",
    "\n",
    "        # Append ToolMessage for LLM to continue\n",
    "        results.append(\n",
    "            ToolMessage(\n",
    "                tool_call_id=call_id,\n",
    "                name=tool_name,\n",
    "                content=str(result_text)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(\"→ Calculator Tools Execution Complete. Returning control to LLM.\\n\")\n",
    "    return {\"messages\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72305a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"llm\", call_llm)\n",
    "graph.add_node(\"retriever_agent\", retrieve_document)\n",
    "graph.add_node(\"calculator_agent\", calculate)\n",
    "\n",
    "# Entry point: first retrieve context for user query\n",
    "graph.set_entry_point(\"llm\")\n",
    "\n",
    "# Conditional routing after LLM\n",
    "graph.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    route_tools,\n",
    "    {\n",
    "        \"retriever\": \"retriever_agent\",\n",
    "        \"calculator\": \"calculator_agent\",\n",
    "        \"none\": END,\n",
    "    }\n",
    ")\n",
    "\n",
    "# After tools → return to LLM\n",
    "graph.add_edge(\"retriever_agent\", \"llm\")\n",
    "graph.add_edge(\"calculator_agent\", \"llm\")\n",
    "\n",
    "# Compile graph\n",
    "rag_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb33325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(rag_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f61000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []\n",
    "\n",
    "user_input = input(\"Enter: \")\n",
    "while user_input != \"exit\":\n",
    "    conversation_history.append(HumanMessage(content=user_input))\n",
    "    result = rag_agent.invoke({\"messages\": conversation_history})\n",
    "    conversation_history = result[\"messages\"]\n",
    "    print(\"\\n=== ANSWER ===\")\n",
    "    print(result['messages'][-1].content)   \n",
    "    user_input = input(\"Enter: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f00e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
